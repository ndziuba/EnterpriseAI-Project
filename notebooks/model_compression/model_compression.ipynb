{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plotter_lib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR**\n",
    "No significant change in model size while pruning; Quantized TFlite model could be worth it, but requires big change in pipeline architecture caused by the TFlite architecture\n",
    "\n",
    "\n",
    "- Size of gzipped baseline Keras model: 89477336.00 bytes\n",
    "- Size of gzipped pruned Keras model: 89477336.00 bytes\n",
    "- Size of gzipped pruned TFlite model: 89287269.00 bytes\n",
    "- Size of gzipped pruned and quantized TFlite model: 20650452.00 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "        directory = \"../../data/test\",\n",
    "        seed = 1324,\n",
    "        label_mode = 'categorical',\n",
    "        image_size = (350, 350),\n",
    "        batch_size=32\n",
    ")\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "        directory = \"../../data/train\",\n",
    "        seed = 1324,\n",
    "        label_mode = 'categorical',\n",
    "        image_size = (350, 350),\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "valid_ds = image_dataset_from_directory(\n",
    "        directory = \"../../data/valid\",\n",
    "        seed = 1324,\n",
    "        label_mode = 'categorical',\n",
    "        image_size = (350, 350),\n",
    "        batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,637,826\n",
      "Trainable params: 1,050,114\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = Sequential()\n",
    "\n",
    "# import pretrained model\n",
    "resnet_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=(350,350,3),\n",
    "    pooling='avg',\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# exclude pretrained model weights from being recalculated\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add pretrained ResNet50 model to sequential model\n",
    "model.add(resnet_model)\n",
    "\n",
    "# add additional layers to model\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, tf.nn.relu))\n",
    "model.add(Dense(2, tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 60s 62ms/step - loss: 0.1088 - accuracy: 0.9637 - val_loss: 0.0601 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d44c2ed00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=valid_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 10s 48ms/step - loss: 0.0449 - accuracy: 0.9863\n",
      "Baseline test accuracy: 0.9863448739051819\n",
      "Saved baseline model to: /tmp/tmpjw4q6k4j.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              47042852  \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 2048)             1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense (  (None, 512)              2097666   \n",
      " PruneLowMagnitude)                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_1  (None, 2)                2052      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,142,571\n",
      "Trainable params: 1,050,114\n",
      "Non-trainable params: 48,092,457\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "validation_split = 0 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = 30247  * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define the pruning parameters\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.50,\n",
    "        final_sparsity=0.80,\n",
    "        begin_step=0,\n",
    "        end_step=5000\n",
    "    )\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 12s 53ms/step - loss: 0.0449 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044921599328517914, 0.9863448739051819]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model_for_pruning, \"models/pruned_model/\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,637,826\n",
      "Trainable params: 1,050,114\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 11s 50ms/step - loss: 0.0449 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04492153227329254, 0.9863448739051819]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_export.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.models.save_model(model_for_export, \"models/stripped_model/\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvoq752je/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvoq752je/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /tmp/tmpqcchwqyn.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 14:58:31.997766: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-07-15 14:58:31.997817: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 89477336.00 bytes\n",
      "Size of gzipped pruned Keras model: 89477336.00 bytes\n",
      "Size of gzipped pruned TFlite model: 89287269.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb4vs2tug/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb4vs2tug/assets\n",
      "2023-07-15 14:59:35.977494: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-07-15 14:59:35.977552: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: /tmp/tmpbha3y0ls.tflite\n",
      "Size of gzipped baseline Keras model: 91415683.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 21231324.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
